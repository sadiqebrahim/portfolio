<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Kartik Narayan</title>

  <meta name="author" content="Kartik Narayan">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/face-icon.png">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:left">
                    <name>Kartik Narayan</name>
                  </p>
                  <p>I am a 2nd year Ph.D. student in the <a href="https://www.cs.jhu.edu">Computer Science
                      department</a>
                    at <a href="https://www.jhu.edu">Johns Hopkins University</a>, where I am a member of <a
                      href="https://engineering.jhu.edu/vpatel36/">VIU lab</a>, advised by <a
                      href="https://engineering.jhu.edu/faculty/vishal-patel/">Dr.Vishal Patel</a>. My research focuses
                    on computer vision and its applications in face analysis, understanding, and recognition, with a
                    particular emphasis on multimodal LLMs and generation.
                  </p>
                  <p>
                    Prior to my doctoral studies, I worked as an undergraduate researcher under
                    <a href="http://home.iitj.ac.in/~richa/">Prof. Richa Singh</a> and
                    <a href="http://home.iitj.ac.in/~mvatsa/">Prof. Mayank Vatsa</a> at the
                    <a href="http://iab-rubric.org">Image Analysis and Biometrics (IAB) Lab</a>,
                    IIT Jodhpur, where I worked on deepfake video generation. During my time at IIT Jodhpur,
                    I also collaborated with
                    <a href="http://home.iitj.ac.in/~suman/">Dr. Suman Kundu</a> and
                    <a href="https://sites.google.com/site/suchetana0116">Dr. Suchetana Chakraborty</a>.
                    Additionally, I interned at the University of Texas, San Antonio, where I worked with
                    <a href="https://drheenarathore.wordpress.com">Dr. Heena Rathore</a> and
                    <a href="https://scholar.google.com/citations?user=w_LvvecAAAAJ&hl=en">Dr. Faycal Znidi</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:kartiknarayan1@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="data/Kartik_Resume.pdf">CV</a> &nbsp/&nbsp
                    <!-- <a href="data/KartikNarayan_bio.txt">Bio</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.com/citations?user=bReNhqAAAAAJ&hl=en&oi=ao">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/kartik-narayan-323584199/">LinkedIn</a> &nbsp/&nbsp
                    <a href="https://twitter.com/KartikNarayan10">Twitter</a> &nbsp/&nbsp
                    <a href="https://github.com/Kartik-3004">Github</a>
                  </p>
<!--                   <p style="text-align:left; font-weight:bold; color:#d9534f;">
                    Open to internship opportunities for Summer 2025
                  </p> -->
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/KartikNarayan.jpeg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/KartikNarayan_circle.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:10px;width:100%;vertical-align:middle">

                  <heading>Research</heading>
                  <p>
                    My research primarily focuses on computer vision and its applications in face analysis,
                    understanding, and recognition,
                    with the goal of developing robust open-world algorithms that can be deployed for real-world impact.
                    My specific
                    research interests include multimodal LLMs and video generation. My current work focuses on MLLM agents, reasoning, and video generation. I have
                    authored multiple
                    first-author papers in top conferences like CVPR, ICCV, AAAI.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <p>
                  <div style="width:100%;overflow-y:scroll; height:200px;">
                    <ul>
                      <li>[June, 2025] <b>One Paper</b> is accepted at <b>ICCV 2025.</b></li>
                      <li>[May, 2025] I will join <b>Apple</b> for Summer 2025.</li>
                      <li>[April, 2025] <b>Two Papers</b> are accepted at <b>FG 2025.</b> </li>
                      <li>[December, 2024] <b>One Paper</b> is accepted at <b>AAAI 2025.</b> </li>
                      <li>[October, 2024] <b>One Paper</b> is accepted at <b>WACV 2025.</b> </li>
                      <li>[October, 2024] <b>One Paper</b> is accepted at <b>IEEE TBIOM.</b> </li>
                      <li>[January, 2024] <b>One Paper</b> is accepted at <b>FG 2024.</b> </li>
                      <li>[August, 2023] Joined as a PhD student at <b>VIU Lab, Johns Hopkins University.</b>
                      </li>
                      <li>[May, 2023] Received <b>CVPR Student Travel Award.</b> </li>
                      <li>[Feb, 2023] <b>One Paper</b> is Accepted at <b>CVPR 2023.</b></li>
                      <li>[September, 2022] <b>One Paper</b> is Accepted at <b>IEEE Access.</b> </li>
                      <li>[August, 2022] <b>One Paper</b> is Accepted at <b>IJCB 2022.</b></li>
                      <li>[April, 2022] <b>One Paper</b> is Accepted at <b>CVPRW TCV 2022.</b></li>
                      <li>[January, 2022] <b>One Paper</b> is Accepted at <b>IEEE SysCon 2022</b>. </li>
                    </ul>
                  </div>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <hr>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                  <p>
                    See my <a href="https://scholar.google.com/citations?user=bReNhqAAAAAJ&hl=en&oi=ao">Google
                      Scholar</a> profile for the complete and most recent publications.<br>
                    Representative papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr bgcolor="#ffffe6" style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/facex_archi.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2403.12960v2">
                    <papertitle><i>FaceXFormer</i>: A Unified Transformer for Facial Analysis
                    </papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>,
                  Vibashan VS,
                  Rama Chellappa,
                  Vishal M. Patel
                  <br>
                  <br>
                  <em><span style="color: brown;">ICCV 2025</span></em>
                  <br>
                  <a href="https://arxiv.org/abs/2403.12960v2">arXiv</a> /
                  <a href="https://kartik-3004.github.io/facexformer/">project</a> /
                  <a href="https://github.com/Kartik-3004/facexformer">code (263 &#x2B50;)</a>
                </td>
              </tr>
              <tr style="height:10px;">
                <td colspan="2"></td>
              </tr>
              <tr bgcolor="#ffffe6" style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/segface.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2412.08647">
                    <papertitle><i>SegFace</i>: Face Segmentation of Long-Tail Classes</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>,
                  Vibashan VS,
                  Vishal M. Patel
                  <br>
                  <br>
                  <em><span style="color: brown;">AAAI 2025</span></em>
                  <br>
                  <a href="https://arxiv.org/abs/2412.08647">arXiv</a> /
                  <a href="https://kartik-3004.github.io/SegFace/">project</a> /
                  <a href="https://github.com/Kartik-3004/SegFace">code (69 &#x2B50;)</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/facexbench.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="papers/facexbench.pdf">
                    <papertitle><i>FaceXBench</i>: Evaluating Multimodal LLMs on Face Understanding</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>, Vibashan VS, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">Under Review</span></em>
                  <br>
                  <a href="https://arxiv.org/abs/2501.10360">arXiv</a> /
                  <a href="https://kartik-3004.github.io/facexbench/">project</a> /
                  <a href="https://github.com/Kartik-3004/facexbench">code</a>
                </td>
              </tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/petalface_intro.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://kartik-3004.github.io/PETALface/">
                    <papertitle><i>PETALface</i>: Parameter Efficient Transfer Learning for Low-resolution Face Recognition</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>, Nithin Gopalkrishnan Nair, Jennifer Xu, Rama Chellappa, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">WACV 2025 (Oral)</span></em>
                  <br>
                  <a href="https://arxiv.org/abs/2412.07771">arXiv</a> /
                  <a href="https://kartik-3004.github.io/PETALface/">project</a> /
                  <a href="https://github.com/Kartik-3004/PETALface">code</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/facemoe.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="papers/FaceMOE.pdf">
                    <papertitle>FaceMoE: Mixture of Experts for Low-Resolution Face Recognition</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">Under Review</span></em>
                  <br>
                  <a href="papers/FaceMOE.pdf">paper</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/tfsa.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2505.22663">
                  <papertitle>Training-Free Stylized Abstraction</papertitle>
                  </a>
                  <br>
                  Aiman Rahman*, <strong>Kartik Narayan*</strong>, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">Under Review</span></em>
                  <br>
                  <a href="https://arxiv.org/pdf/2505.22663">arXiv</a> /
                  <a href="https://kartik-3004.github.io/TF-SA/">project</a> /
                  <a href="https://github.com/Kartik-3004/TF-SA">code</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/restorevar.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2505.18047">
                  <papertitle>RestoreVAR: Visual Autoregressive Generation for All-in-One Image Restoration</papertitle>
                  </a>
                  <br>
                  Sudarshan Rajagoplan, <strong>Kartik Narayan</strong>, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">Under Review</span></em>
                  <br>
                  <a href="https://arxiv.org/pdf/2505.18047">arXiv</a> /
                  <a href="https://sudraj2002.github.io/restorevarpage/">project</a> /
                  <a href="https://github.com/sudraj2002/RestoreVAR">code</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/INFER.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="papers/INFER.pdf">
                  <papertitle>INFER: Implicit Neural Features for Exposing Realism</papertitle>
                  </a>
                  <br>
                  Dhananjaya Jayasundara, <strong>Kartik Narayan</strong>, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">Under Review</span></em>
                  <br>
                  <a href="papers/INFER.pdf">paper</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/bias.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="papers/FG2025_Bias_MLLM.pdf">
                  <papertitle>Investigating Social Biases in Multimodal LLMs</papertitle>
                  </a>
                  <br>
                  Malsha Perera*, <strong>Kartik Narayan*</strong>, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2025</span></em>
                  <br>
                  <a href="papers/FG2025_Bias_MLLM.pdf">paper</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/briar.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="papers/FG2025_SwinFR.pdf">
                  <papertitle>Improved Representation Learning for Unconstrained Face Recognition</papertitle>
                  </a>
                  <br>
                  Nithin Gopalkrishnan Nair*, <strong>Kartik Narayan*</strong>, Maitreya Suin, Ram Prabhakar, Jennifer Xu, Soraya Stevens, Joshua Gleason, Nathan Shnidman, Rama Chellappa, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2025</span></em>
                  <br>
                  <a href="papers/FG2025_SwinFR.pdf">paper</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/hypoc_archi.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2404.14406">
                    <papertitle><i>Hyp-OC</i>: Hyperbolic One Class Classification for Face Anti-Spoofing</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>, Vishal M. Patel
                  <br><br>
                  <em><span style="color: brown;">IEEE International Conference on Automatic Face and Gesture Recognition (FG) 2024</span></em>
                  <br>
                  <a href="https://arxiv.org/pdf/2404.14406">paper</a> /
                  <a href="https://kartik-3004.github.io/hyp-oc/">project</a> /
                  <a href="https://github.com/Kartik-3004/hyp-oc">code</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr bgcolor="#ffffe6" style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/dfplatter.jpeg' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Narayan_DF-Platter_Multi-Face_Heterogeneous_Deepfake_Dataset_CVPR_2023_paper.html">
                    <papertitle><i>DF-Platter</i>: Multi-subject Heterogeneous Deepfake Dataset</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>,
                  Harsh Agarwal,
                  Kartik Thakral,
                  Surbhi Mittal,
                  Mayank Vatsa,
                  Richa Singh
                  <br>
                  <br>
                  <em><span style="color: brown;">CVPR 2023</span></em>
                  <br>
                  <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Narayan_DF-Platter_Multi-Face_Heterogeneous_Deepfake_Dataset_CVPR_2023_paper.pdf">paper</a> /
                  <a href="data/DF-Platter_Poster.pdf">poster</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/deephynet.png' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10737137">
                    <papertitle><i>DeePhyNet</i>: Towards Detecting Phylogeny in Deepfakes</papertitle>
                  </a>
                  <br>
                  Kartik Thakral, Harsh Agarwal, <strong>Kartik Narayan</strong>, Surbhi Mittal, Mayank Vatsa, Richa Singh
                  <br><br>
                  <em><span style="color: brown;">IEEE Transactions on Biometrics, Behavior, and Identity Science (T-BIOM)</span></em>
                  <br>
                  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10737137">paper</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/ijcb.jpg' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10007968/">
                    <papertitle><i>DeePhy</i>: On Deepfake Phylogeny</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>, Harsh Agarwal, Kartik Thakral, Surbhi Mittal, Mayank Vatsa, Richa Singh
                  <br><br>
                  <em><span style="color: brown;">International Joint Conference on Biometrics (IJCB) 2022 (Oral)</span></em>
                  <br>
                  <a href="https://arxiv.org/pdf/2209.09111">paper</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/desi.jpg' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://openaccess.thecvf.com/content/CVPR2022W/FaDE-TCV/html/Narayan_DeSI_Deepfake_Source_Identifier_for_Social_Media_CVPRW_2022_paper.html">
                    <papertitle><i>DeSI</i>: Deepfake Source Identifier for Social Media</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>, Harsh Agarwal, Surbhi Mittal, Kartik Thakral, Suman Kundu, Mayank Vatsa, Richa Singh
                  <br><br>
                  <em><span style="color: brown;">CVPR Workshops 2022</span></em>
                  <br>
                  <a href="https://openaccess.thecvf.com/content/CVPR2022W/FaDE-TCV/papers/Narayan_DeSI_Deepfake_Source_Identifier_for_Social_Media_CVPRW_2022_paper.pdf">paper</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/access.jpg' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9893130">
                    <papertitle>Using Epidemic Modelling, Machine Learning and Control Feedback Strategy for Policy Management of COVID-19</papertitle>
                  </a>
                  <br>
                  <strong>Kartik Narayan</strong>, Heena Rathore, Faycal Znidi
                  <br><br>
                  <em><span style="color: brown;">IEEE Access 2022</span></em>
                  <br>
                  <a href="papers/Access.pdf">paper</a> /
                  <a href="https://github.com/Kartik-3004/SIR_pandemic">code</a>
                </td>
              </tr>
              <tr style="height:10px;"><td colspan="2"></td></tr>
              <tr style="height:110px;">
                <td style="padding:10px;width:25%;vertical-align:middle">
                  <div style="text-align: center">
                    <img src='images/syscon_2.jpg' width="180", height="112.5", style="display: block;">
                  </div>
                </td>
                <td style="padding:10px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9773844">
                    <papertitle>Leveraging ambient sensing for the estimation of curiosity-driven human crowd</papertitle>
                  </a>
                  <br>
                  Anirban Das, <strong>Kartik Narayan</strong>, Suchetana Chakraborty
                  <br><br>
                  <em><span style="color: brown;">IEEE Systems Conference (SysCon) 2022</span></em>
                  <br>
                  <a href="https://ieeexplore.ieee.org/abstract/document/9773844">paper</a>
                </td>
              </tr>

            </tbody>
          </table>

          <table width="100%" ;align="center" ;border="0px" ;cellspacing="0" ;cellpadding="20">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    <a href="https://jonbarron.info/">Template credits</a>. Last updated June 2025.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>


</body>

</html>
